---
title: "SIGGRAPH 2018 总结"
categories:
  - Conference
date:   2018-10-05 16:12:00 +0800
tags:
  - Graphics
---

<script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>


## SIGGRAPH 2018
今年的 SIGGRAPH 在加拿大温哥华举办，历史上来说，SIGGRAPH 在洛杉矶举办的次数是最多的，得益于它是好莱坞的所在地，基本上也只有在洛杉矶举办才是赚钱的，恰好温哥华的电影工业也是高度发达，被称为”北方好莱坞”，因此也非常适合 SIGGRAPH 的举办，今年也是温哥华第二次迎来 SIGGRAPH。

### 第一天
我们早早来到了 Vancouver Convention Centre，会议的举办地，毗邻港口，风景宜人，标志性的像素海豚是众多游客拍照留念的地方。

<figure>
<img src="/assets/images/siggraph18/1.png" alt="what"/>
<figcaption> <center>Convention Centre</center> </figcaption>
</figure>
<br/>


<figure>
<img src="/assets/images/siggraph18/2.png" alt="what"/>
<figcaption> <center>港口的游轮，每天都不一样</center> </figcaption>
</figure>
<br/>

<figure>
<img src="/assets/images/siggraph18/3.png" alt="what"/>
<figcaption> <center>像素海豚</center> </figcaption>
</figure>
<br/>

会议前一天下午就可以注册了，我们抵达的时候已经是排起了长队。

<figure>
<img src="/assets/images/siggraph18/4.png" alt="what"/>
<figcaption> <center>会场入口</center> </figcaption>
</figure>
<br/>

<figure>
<img src="/assets/images/siggraph18/5.png" alt="what"/>
<figcaption> <center>注册队伍</center> </figcaption>
</figure>
<br/>
一切准备完毕后，就是等待开启长达5天的 CG 盛宴之旅。

### Agenda
会议提供了专门的 APP，可以看到所有的 session，包括简介，时间，地点等等信息，参会者就可以很方便的安排自己的日程，挑选自己感兴趣的 Topic，这一点非常重要，因为 SIGGRAPH 包含了大量的 session，在同一个时间段就可能有5，6个是重叠的，一个人是不可能听完所有的讲座的，所以我的总结中也只能尽可能覆盖我自己所参加的部分。
总的来说，会议包含大致这几个部分：

*Technical Papers*：这是会议中最学术的环节，全世界最顶尖的图形学研究者会在讲座中讲解他们所发表的 paper。

*Posters*：同样是学术的环节，有趣的但不足以成为 technical paper 的研究可以作为 poster 在会场展示。

*Exhibition*：新技术的展示，在一个大的展厅内分布着众多摊位，向参会者展示他们的创意和技术。这次仍然有大量的 VR, AR 技术和内容的展示。

*Electronic Theatre*： 需要单独购票的环节，也就是 Computer Animation Festival，会在一个超大的放映厅播放今年参赛的计算机动画。

*Realtime Live*：类似于 Computer Animation Festival，不同的是这里都是 Realtime  demo的展示 。

*Social Events*：Chapter Party，Khronos events，Asian meetup 等等。

*Training*： Vulkan，WebGL 等等入门课程。

下面就分类逐一聊聊我的所见所闻。

### Talks & Technical Paper

#### Confocal non-line of sight imaging
 
<figure>
<img src="/assets/images/siggraph18/6.png" alt="what"/>
<figcaption> <center>检测隐藏的 Bunny</center> </figcaption>
</figure>
<br/>
Non-line-of-sight imaging，也就是”非视线成像”，在2012年被提出，最初是由科学家 Antonio Torralba 在旅馆里偶然发现墙上的影子其实并非真正由于遮挡而产生的影子，而是窗外庭院通过窗户这个”小孔相机”在墙壁上的成像，这让科学家们意识到我们的真实世界中包含大量肉眼不可见的成像信息。Antonio 因此开始了对这种”意外相机”的研究，被称为”非视线成像”。

在之后的研究中，包含不少通过分析阴影来推断附近场景的工作，也出现了通过专业激光相机来检测被遮挡的物体，这个 Talk 就来自于这一类，通过专业相机朝墙壁上发射激光脉冲，光子会被反射到隐藏的物体上，并且发生散射，然后程序通过检测光子反射回相机所经历的时间，来推断隐藏的物体的几何结构。

来自 MIT 的研究人员将这个系统做到了 Realtime，能实时地检测和三维重建被遮挡的物体，效果非常惊艳，这在无人汽车，军事和救援中相信都能发挥巨大的作用，他们也带来了 demo 给大家展示和体验。
 <figure>
<img src="/assets/images/siggraph18/7.png" alt="what"/>
<figcaption> <center>实时检测 Demo</center> </figcaption>
</figure>
<br/>
 <figure>
<img src="/assets/images/siggraph18/8.png" alt="what"/>
<figcaption> <center>实时检测 Demo</center> </figcaption>
</figure>
<br/>
     
图 5  实时检测和重建
#### Muon Pyramid Scan
Muon 叫做渺子或者μ介子，是宇宙射线进入大气层后的产物，这项研究是通过检测渺子在金子塔内部结构中的运动变化来重建金字塔内部结构，类似于 x 射线的作用。
渺子的运动变化需要利用软件进行复杂的物理模拟，这个 talk 就是给出了一个基于3D 引擎的实时模拟器。

 <figure>
<img src="/assets/images/siggraph18/9.png" alt="what"/>
<figcaption> <center>这项技术被用在了胡夫金字塔内部结构的检测上</center> </figcaption>
</figure>
<br/>
#### Integrating Clipped Spherical Harmonics Expansion
解析地计算球谐函数积分来实现实时的面光源光照，这跟之前 Eric Heitz 的“Real-Time Polygonal-Light Shading with Linearly Transformed Cosines” 实现的实时面光源很像，但是 Eric 的方法不能解决面光源产生的阴影，而这篇文章解决了这个问题，并且在 mobile 上能实现 Realtime，文中给出的结果是在三星 s8上， Stanford Dragon场景，4阶球谐函数，能够获得30 fps。

<figure>
<img src="/assets/images/siggraph18/10.png" alt="what"/>
<figcaption> <center>实时面光源</center> </figcaption>
</figure>
<br/>

#### MegaTree: A Hardware HLBVH Constructor for Animated Ray Tracing
这篇文章提出了一个硬件架构来对 Ray tracing 中常用的空间划分结构进行加速。这个架构主要是针对只有有限带宽资源的 mobile 设备。
对于动态场景，更新空间划分加速结构是非常 memory-intensive 的，这篇文章提出的硬件架构是第一个针对 Hierarchical Linear Bounding Volume Hierarchy（HLBVH）的硬件加速，相对于算法的软件实现，带宽节省了3倍以上。在 HLBVH 的创建速度上也比当前流行的 binned SAH builder 快了5倍。

#### Tetrahedral Meshing in the Wild
这篇文章给出了革命性的方法来高质量地从普通的 triangle mesh 构建出 tetrahedral mesh。过程包括 Delaunay triangulation， Binary subdivision等等，生成的 tetrahedral mesh 具有内部结构，唯一的不足是对于非常尖锐的部分无法很好的保留细节，但是即使这样我发现效果在很尖锐的部分也已经很好了。
论文的实现是开源的。
 
<figure>
<img src="/assets/images/siggraph18/11.png" alt="what"/>
<figcaption> <center>Tetrahedral Mesh</center> </figcaption>
</figure>
<br/>


#### Curved Optimal Delaunay Triangulation
 这是将传统 triangle mesh 网格通过Delaunay triangulation fit 到外部自定义的形状上，并且由curved triangle mesh 来表示。Curved triangle mesh 相对于传统 triangle mesh 来说表达能力更强，所需要的面也更少，但是生成这样的 mesh 是非常耗时的。
这篇文章提出的基于 GPU 加速的方法可以只用50秒将200个顶点的 mesh fit 为对应的 curved triangle mesh。

#### Shape from Metric
非常 fancy 的 demo 展示，将一个 Stanford Bunny 从内到外翻了个面，demo 一秀出来全场都忍不住鼓掌，文章花了不少篇幅讲解这种几何变形会遇到的 pinch point，以及如何避免，但是内容涉及太高深的数学，我也只能看个热闹了。

<figure>
<img src="/assets/images/siggraph18/12.png" alt="what"/>
<figcaption> <center>从内到外翻转的兔子</center> </figcaption>
</figure>
<br/>
#### Rendering Specular Microgeometry with Wave Optics
通常光照计算中都将光线表达为射线，这叫做 geometric optics，而 wave optics 则是将光线表达为波，这样一来光线的反射就变成了波的形变。
这种表示在渲染带划痕的金属制品时更加方便，文章提供的方法可以高质量地渲染单个或多个波长下的微表面反射。
<figure>
<img src="/assets/images/siggraph18/13.png" alt="what"/>
<figcaption> <center>Wave Optics</center> </figcaption>
</figure>
<br/>
 

#### A High-Performance Software Graphics Pipeline Architecture for the GPU
一个 D3D9风格的 pipeline的软件实现，包括光栅化，但是使用了硬件的 texture units。
这样的软件管线可以灵活地针对特殊 case 进行优化，文章中提出了一个高度场生成的例子，在 hardware pipeline 下需要3个 pass，但是在他们的软件实现中只需要1个 pass。
总体来说他们的软件渲染管线的性能跟硬件加速的渲染管线差距在1个数量级内，对于最好的情况，差距在2倍以内。
但是他们的性能测试是通过抓取游戏的几何数据，然后用他们自己的 shader 来进行的渲染，所以不见得能体现最真实的性能情况。
最后，他们的实现也是开源的。

#### Slang: Language Mechanisms for Building Extensible Real-Time Shading Systems
针对当前 shader 编写和管理的复杂性，提出的一个 基于 HLSL 的扩展，将 shader 模块化，并且不会引入虚函数，保持了静态特性，因为虚函数在 gpu 上会非常低效。
模块化指的是对于 lighting，material deformation 等等计算，都可以直接使用现成实现，由 compiler 直接插入到 shader 中，可以看做静态的多态，这里面包括了不少现代编译器的技术。
现有的一些解决方案比如，engine specific 的语法和编译器，但是难以扩展到其他引擎，preprocessor 的方法，就是一大堆 ifdef，完全不模块化。
Slang 已经在 NVIDIA 内部一些实验项目中使用了。

#### Google’s Light Fields VR
利用光场相机抓取场景中的光照信息，在 VR 中真实还原场景的技术。
通常的方法使用360度相机拍摄场景，但是这样的方法无法提供动态的光照，也就是说在 VR 体验中，光线无法随你的视角变化而变化（比如specular），并且在 VR 中图像有很大的桶形畸变，最后用户无法在场景中移动，只能进行旋转视角。

<figure>
<img src="/assets/images/siggraph18/14.png" alt="what"/>
<figcaption> <center>Google的光场相机设置</center> </figcaption>
</figure>
<br/>
Google 利用一个 GoPro 阵列，旋转一圈拍摄场景，然后在球面上均匀采样出一部分 image，相邻的 image 利用视差计算出深度信息，深度信息用于构建网格来做动态光照。
他们提供了 demo 供大家体验，并且他们的光场数据在 steam 上还可以下载体验。

#### Fractal multiverses in VR
我非常感兴趣的一个讲座，因为很喜欢分形渲染，他们应该是做出了目前体验最好的在 VR 中进行分形探索的 demo。
算法仍然是基于经典的 Raymarching，但是分形渲染的计算量是相当大的，Naïve 的方法下，raymarching 的每一步都需要计算到整个分形的距离，而这个计算不但复杂，还通常是一个循环，为了能在 VR 中实时的渲染，他们加入了非常多加速技巧，包括很多来自 demoscene的 trick，比如， Hierarchical accelerated sphere tracing 用于加速marching，cone-marching用于实现 dof 和抗锯齿，stereo reprojection用于让双眼图像只需要渲染一次，fixed foveated rendering 用于减少需要计算的像素，fake ambient occlusion 利用分形计算的中间结果来伪造环境光遮蔽，subsurface scattering 用于次表面散射，rim lighting without a normal 用于省去多余的 法线计算等等。

#### Embree Raytracing Kernel from Intel
去听了一小会儿，门外排着超长的队伍等着听隔壁皮克斯的讲座。后来有点后悔，应该去皮克斯领茶壶的。
这个是Intel 自己的 raytracing 软件实现，包含 raytracing 中的各种空间划分加速算法，支持各种 primitive的求交，而且这些算法都是经过 SIMD 的充分优化。这个库的使用也很方便，很适合用于学习和用作 ground truth 计算等等，在今年 RTX 的光芒下，这个就显得不那么酷了。

#### RTX on Vulkan
NVIDIA 的 RTX 可以说是今年图形学界最火的一个话题了。可惜我并没有去黄老板的现场，但是还好没有错过 RTX 在 Vulkan 上的支持。
Vulkan raytracing 的 Extension 已经在不断完善的阶段了，从最新的 Vulkan 1.1.xx的 spec 中都已经可以看到 raytracing 的 shader stages，现在这个 extension 叫做 VK_NV_raytracing，它提出的 pipeline 是这样的：
 
<figure>
<img src="/assets/images/siggraph18/15.png" alt="what"/>
<figcaption> <center>Raytracing Pipeline</center> </figcaption>
</figure>
<br/>

Shader stage也和光栅化完全不同了，在 raytracing 中，有以下几种 shader:
Ray Generation Shader， Intersection Shader， Any-hit Shader， Cloest-hit Shader， Miss Shader， 他们的关系是：

<figure>
<img src="/assets/images/siggraph18/16.png" alt="what"/>
<figcaption> <center>Raytracing Shader Stages</center> </figcaption>
</figure>
<br/>
除了新加入的 shader，还有 raytracing 所必须的加速结构，vulkan 中会加入新的 structure 和 command 来创建加速结构：
•	vkAccelerationStructureNV
•	vkCmdBuildAccelerationStructureNV
#### Posters
Poster 在会场的一个区域集中展示，几天以来都是一直贴在那里的，其中最喜欢的一个也是分形的渲染，通过体渲染来探索分形的内部结构，以前是没有看到过的。
还发现了很多脑洞大开的研究，特别是来自日本的研究，常常给人一种跑偏了的感觉，比如通过分析面部在咀嚼中的形变来确定食物的硬度这种。

#### Exhibition
展出和体验其实包含几个不同的种类，我就都放这里一起写了。


<figure>
<img src="/assets/images/siggraph18/17.png" alt="what"/>
<figcaption> <center>其中一个场馆</center> </figcaption>
</figure>
<br/>

<figure>
<img src="/assets/images/siggraph18/18.png" alt="what"/>
<figcaption> <center>来自91年的 VR 头盔</center> </figcaption>
</figure>
<br/>
 
<figure>
<img src="/assets/images/siggraph18/19.png" alt="what"/>
<figcaption> <center>增强现实 demo，有各种动物冒出来，不过不会与体验者互动</center> </figcaption>
</figure>
<br/> 
 
<figure>
<img src="/assets/images/siggraph18/20.png" alt="what"/>
<figcaption> <center>来自日本大学生的增强现实游戏，要击败只有通过手机屏幕才能看见的鬼魂</center> </figcaption>
</figure>
<br/> 
 
 
<figure>
<img src="/assets/images/siggraph18/21.png" alt="what"/>
<figcaption> <center>也是来自日本大学生的研究，在水中投影出的3D 影像，体验者如果捧出一捧水，会感觉将水中的影像也一同捧了出来，让我感觉猴子捞月就要率先在日本成功了</center> </figcaption>
</figure>
<br/>


<figure>
<img src="/assets/images/siggraph18/22.png" alt="what"/>
<figcaption> <center>来自日本学生的创新，具有宽视域的3D 显示设备</center> </figcaption>
</figure>
<br/>

<figure>
<img src="/assets/images/siggraph18/23.png" alt="what"/>
<figcaption> <center>来自日本学生的创新，基于视网膜投影的3D 显示设备</center> </figcaption>
</figure>
<br/>

<figure>
<img src="/assets/images/siggraph18/24.png" alt="what"/>
<figcaption> <center>也是来自日本，表情会随被拍摄者变化的机器人</center> </figcaption>
</figure>
<br/> 
 
<figure>
<img src="/assets/images/siggraph18/25.png" alt="what"/>
<figcaption> <center>同样来自日本大学生，图像投射在石榴一样的高速旋转的铁球上，呈现出的三维影像</center> </figcaption>
</figure>
<br/> 

还有一些我没有保存照片的体验，比如迪士尼利用 VR 做的一个短片”cycles”，让人身在场景中体验了动画短片中一个家庭的兴衰变化，还有来自 Square Enix 的”Tales of the Wedding Rings“ VR 漫画，让我第一次感受到了真正置身于漫画场景当中。
#### Computer Animation Festival
非常震撼的体验，现场是这样的：
<figure>
<img src="/assets/images/siggraph18/26.png" alt="what"/>
<figcaption> <center>Electronic Theatre</center> </figcaption>
</figure>
<br/> 
 
开场还有大鼓表演，动画放映过程中是不许拍照的，但是其中有不少动画短片都是网上找得到的，比如有来自 Unity 的宣传 Unity 5 强大渲染能力的 demo: “ Book of the dead”, 来自 NVIDIA 的 RTX 渲染的星球大战 demo，来自皮克斯的华人导演的短片”bao”，如果你去电影院看过”超人总动员2”想必你就已经看过这个短片了，还有来自中国太崆动画的短片”冲破天际” 也让我惊讶了一把，华人在 CG 行业也逐渐开始崭露头角了。
短短几个小时，带给我太多震撼和感动，不由得心里暗暗感叹，这票买的值了。


#### Realtime Live!
与 Computer Animation Festival 在同一个地方，不同的是，所有的 demo 都是实时的，于是有不少 VR，AR 的 demo，并且有很多交互和互动。
<figure>
<img src="/assets/images/siggraph18/27.png" alt="what"/>
<figcaption> <center>Realtime Live</center> </figcaption>
</figure>
<br/> 

印象深刻的 demo 有: 实时通过手机的面部捕捉，并且与3D avatar 绑定，实时的反应被捕捉者的面部表情，demo 采用的 avatar 是个胖小孩，跟演示者搞怪的表情同步，显得非常有趣，这个 demo 也夺得了 realtime live 的冠军。还有带着 VR 眼镜拿着手柄进行肠道手术游戏的 demo，左手钳子夹掉肠道中的肿瘤，右手激光枪灼烧修复伤口，它们实现了非常真实的极具肉感的肠道，真实的血液流动，demo 感觉很恶心但又让人欲罢不能。

最后一个让我特别震撼的就是虚拟拍摄技术，在这之前我甚至都不知道这个技术的存在，演示这个技术的又是 RTX 的星球大战 demo，这一次两位演示者带上 VR 眼镜进入到了这个实时渲染的 demo 中，他们分别扮演在 demo 中的两位风暴士兵，并且他们决定实时地改变 demo 的剧情，也就是利用虚拟拍摄技术，让带着 VR 眼镜的演员实时地演出 demo 中的虚拟角色，其中一位演示者在场景中设置好了虚拟摄像机，然后开拍，两位由演示者扮演的风暴士兵的新的台词和动作就被重新记录下来，并且马上就能无缝衔接到 demo 中进行重新播放。

之后 Unity 也在他们的引擎中演示了类似的虚拟拍摄技术，可以想象游戏引擎在将来在 CG 行业中将会扮演更加重要的角色，对于电影的制作，动画的制作都可能出现颠覆性的影响。



#### Misc
毕竟 CG 跟电影行业息息相关，也有不少电影特效制作的分享，比如权利的游戏，复仇者联盟: 无限战争，对于这些电影中一些精彩镜头的特效是如何一步一步被制作出来的，给出了 非常详细的解析，特别是对于刚看完复联不久的我，算是大开眼界，虽然这些 session 都是不允许拍照的，但是至少能拍拍排队等待进场的人:

<figure>
<img src="/assets/images/siggraph18/28.png" alt="what"/>
<figcaption> <center>最后一天，复仇者联盟：无限战争的制作</center> </figcaption>
</figure>
<br/> 

这是最后一天的最后一个 session，复仇者联盟：无限战争的制作分享，排着超长的队伍，可见大家的热情之高。

在动画方面，VR 的进入带来了一定程度观影方式的改变，比如之前提到的迪士尼的” cycles”，还有一个讲述印第安传说中的英雄的故事” crow the legend”，观影者需要通过 VR 与故事中的主角交互，比如用手挥舞帮助主人公驱散前进路上的障碍物，虽然现在的交互并不会改变故事走向，但还是非常期待这种新颖的动画形式能够更加成熟和普及。
SIGGRAPH 的 Social Event，Chapter party 我们是错过了，因为公司的内部聚会，非常可惜，听说当晚 Ken Perlin 也在，也就是柏林噪声之父，要能合个影就好了。不过后来我去参加了一个 Asian meetup，认识了不少电影特效行业的朋友，还见到了一直致力于记录国内古董电子文化和艺术历史的蓬岸小哥，他的知乎专栏叫做”古董电脑室”，和他聊了一晚上国内 demoscene 文化的发展，收获很大，这也是 SIGGRAPH 的魅力之一吧，除了围观大牛，还能认识 CG 领域里不同行业的人，结交志同道合的朋友。
#### 结语
我所能记录下的只是 SIGGRAPH 的一小部分而已，还有不少我根本来不及参加的 session，以及不少来不及去体验的新技术新应用，但是我仍然充分体验到为什么有人说去 SIGGRAPH 就是去朝圣，如果你热爱CG，一定要去 SIGGRAPH 瞧瞧。

